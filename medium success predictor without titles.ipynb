{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data and format it\n",
    "df = pd.read_csv('articles.csv', names = [\"Claps\", \"Title\",\"Text\"])\n",
    "claps = df.pop('Claps').values\n",
    "features = df.pop(\"Text\").values\n",
    "train_features, test_features, train_claps, test_claps = train_test_split(features, claps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reusable formatting function\n",
    "def preprocess(arr):\n",
    "    #tokenize\n",
    "    tokenizer = Tokenizer(num_words=15_000, oov_token='<UNK>')\n",
    "    tokenizer.fit_on_texts(arr)\n",
    "\n",
    "    #index\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    #sequence\n",
    "    sequences = tokenizer.texts_to_sequences(arr)\n",
    "\n",
    "    #find max sequence length\n",
    "    maxlen = max([len(x) for x in sequences])\n",
    "\n",
    "    #padding \n",
    "    train_padded = pad_sequences(sequences, padding='post', truncating='post', maxlen=maxlen)\n",
    "    print (train_padded)\n",
    "    \n",
    "    return train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  599    19  2158 ...     0     0     0]\n",
      " [    4   503  4633 ...     0     0     0]\n",
      " [   32 11340    10 ...     0     0     0]\n",
      " ...\n",
      " [ 3375 11302  2632 ...     0     0     0]\n",
      " [  190     1  4280 ...     0     0     0]\n",
      " [ 2750   221     1 ...     0     0     0]]\n",
      "[[5492 5493 5494 ...    0    0    0]\n",
      " [ 937   85    3 ...    0    0    0]\n",
      " [  30  192  654 ...    0    0    0]\n",
      " ...\n",
      " [  29   11 2286 ...    0    0    0]\n",
      " [ 775 2593  475 ...    0    0    0]\n",
      " [  12    5  646 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "#format train and test data\n",
    "train_features = preprocess(train_features.tolist())\n",
    "test_features = preprocess(test_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Structure\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(15_000, 20))\n",
    "#model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.LSTM(128))\n",
    "#model.add(keras.layers.Dense(20, activation = \"softmax\"))\n",
    "#model.add(keras.layers.Dense(20, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"relu\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 134s 954ms/sample - loss: 0.9560 - accuracy: 0.7357 - val_loss: 0.5768 - val_accuracy: 0.7833\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 89s 638ms/sample - loss: 0.6462 - accuracy: 0.7357 - val_loss: 0.5209 - val_accuracy: 0.7833\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 91s 649ms/sample - loss: 0.5890 - accuracy: 0.7357 - val_loss: 0.5580 - val_accuracy: 0.7833\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 87s 624ms/sample - loss: 0.5944 - accuracy: 0.7357 - val_loss: 0.5558 - val_accuracy: 0.7833\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 87s 625ms/sample - loss: 0.5892 - accuracy: 0.7357 - val_loss: 0.5424 - val_accuracy: 0.7833\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "fitmodel = model.fit(train_features, train_claps, epochs = 5, batch_size = 50, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 15s 225ms/sample - loss: 0.6247 - accuracy: 0.7164\n",
      "[0.6120317667277891, 0.7164179]\n"
     ]
    }
   ],
   "source": [
    "#results \n",
    "print(model.evaluate(test_features, test_claps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('viralOrNahNoTitles.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = keras.models.load_model('viralOrNahNoTitles.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will your article go viral? Enter your article content to find out: \n",
      "So the US is hitting a wall in vaccine uptake. Practically everyone who wants one is getting one. But way too many have chosen not to get vaccinated. Their choice is devastating to defeating this pandemic. Slow vaccine uptake will give the virus more opportunity to mutate. Mutations will mean we never achieve herd immunity. That this issue has been politicized is deeply frustrating. I would have thought the Trump Republicans would have been celebrating the vaccine — didn’t President Trump claim to be responsible for it happening so quickly? But it is almost as if they are willing this process to fail, so as to gain the political advantage from that failure. (Each time I think cynicism can’t sink lower …) But regardless, what we need now is an aggressive experiment to see what would get the reluctant to get vaccinated. Here are three experiments that we should launch immediately: In one population, we explain to the public the need, but then mandate vaccinations for everyone. (Yes, there’s the emergency use limitation, etc., but let’s authorize an override and move forward.) In another population, we pay people $100, cash, on the spot. They show up with an ID and a social security number, they go home vaccinated with a Ben Franklin in their pocket. (Yes, anyone who has already been vaccinated can also apply for the $100.) In a third population, we inform the public that any vaccines not used by a certain date will be donated to Mexico and developing nations around the world, and no longer available to them. I know which experiment I want to win. But regardless of which does, let’s just get this done.\n",
      "[[ 15   2  47   4  48   7  49   8  16  26  50  27  28  51  17   4  52  17\n",
      "    5  53  54  55  18  56  29   3   9  10  30  57   4  58   3  59  11  60\n",
      "   61  16  26  19  62   2  63  64  65   3  66  67  19  68   6  69  70  71\n",
      "   72  12  11  73  31  20  74   4  75  76  13  21  18  77   2  32  78  21\n",
      "   18  20  79   2  16  80  81  82  32  83   3  33  84  22  34  85  15  86\n",
      "    5  34   4  87  35  88  23  36  89  11  90   3  91  15  35   3  92   2\n",
      "   93  94  95  12  96  97  98  13  99 100 101 102 103 104   5  37  38   6\n",
      "   39 105   4  24 106  40   3 107  38  21   9   2 108   3   9  10 109  36\n",
      "  110 111  12   6 112 113 114   8  17  25   6 115   3   2  41   2  39   5\n",
      "  116 117 118  22  27  42 119   2 120 121 122 123   5  43 124  24 125  14\n",
      "  126 127   8 128  25   6 129 130  44 131 132   2 133  23 134 135  45  24\n",
      "  136  14   7 137 138 139  23 140 141  10  45   7 142 143   8  30 144  42\n",
      "  145  28  31 146  20  10 147 148 149  22   2  44   8   7 150  25   6 151\n",
      "    2  41  12 152 153  29 154 155   7 156 157  19  33 158   3 159  14 160\n",
      "  161 162   2 163  14 164 165 166   3 167  13 168  46  40  13 169   3 170\n",
      "    5  37 171  46 172  43 173   9  11 174]]\n",
      "[[0.13635883]]\n",
      "Your article seems to have a  24.239218235015866 % chance of getting at least 5 thousand claps\n",
      "congrats! looks like you're gonna go viral! Of course, this is just content-wise, make sure to share your story and promote it wherever you can!\n"
     ]
    }
   ],
   "source": [
    "#get input\n",
    "print(\"Will your article go viral? Enter your article content to find out: \")\n",
    "article = [str(input())]\n",
    "\n",
    "#format it \n",
    "userFeatures = preprocess(article)\n",
    "#predict\n",
    "prediction = model.predict(userFeatures)\n",
    "prediction_adjusted = prediction/0.125\n",
    "prediction_adjusted_percent = ((prediction[0][0]-0.1)/0.15)*100\n",
    "print(prediction)\n",
    "#give results\n",
    "if prediction_adjusted[0][0] >= 1:\n",
    "    print(\"Your article seems to have a \", prediction_adjusted_percent, \"% chance of getting at least 5 thousand claps\" )\n",
    "    print(\"congrats! looks like you're gonna go viral! Of course, this is just content-wise, make sure to share your story and promote it wherever you can!\")\n",
    "elif prediction_adjusted[0][0] < 1: \n",
    "    print(\"Your article seems to have a \", prediction_adjusted_percent, \"% chance of getting at least 5 thousand claps\" )\n",
    "    print(\"sorry, this doesn't look like viral material. make some edits and try again\")\n",
    "else: \n",
    "    print(\"I have no idea what is going on right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
